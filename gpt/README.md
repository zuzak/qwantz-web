# qwantz-gpt

The GPT-2 models here were generated by taking 60,000 lines of Dinosaur Comics
transcripts and running them through [Google Collaboratory](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce).

We then ran it through a converter to generate an output useful to [gpt2tc](https://bellard.org/nncp/gpt2tc.html),
which we're using for on the fly GPT-2 text completion.

gpt2tc is closed source, so it's not bundled in this repository.
You can download it from the link above, and extract it to this directory.
